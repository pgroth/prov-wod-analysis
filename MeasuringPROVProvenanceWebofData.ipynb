{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring PROV Provenance on the Web of Data\n",
    "\n",
    "* Authors: \n",
    "    * [Paul Groth](http://pgroth.com), [Elsevier Labs](http://labs.elsevier.com)\n",
    "    * [Wouter Beek](http://www.wouterbeek.com), Vrije Universiteit Amsterdam\n",
    "* Date: May 11, 2016\n",
    "\n",
    "One of the motivations behind the original charter for the [W3C Provenance Incubator group](https://www.w3.org/2005/Incubator/prov/charter) was the need for provenance information for Semantic Web and Linked Data applications. Thus, a question to ask, three years after the introduction of the [W3C PROV family of documents](https://www.w3.org/TR/prov-overview/), is what is the adoption of PROV by the Semantic Web community.\n",
    "\n",
    "A proxy for this adoption is measuring how often PROV is used within Linked Data. In this work, we begin to do such a measurement. Our analytics are based on the [LOD Laundromat](http://lodlaundromat.org/) (Beek et al. 2014). The LOD Laudromat crawls and cleans over 650 thousand linked data documents representing over 38 billion triples. LOD Laudromat has been used in the past to do large scale analysis of linked data (Rietveld et al. 2015). \n",
    "\n",
    "Here, we focus on core statistics based around what [PROV-DM](http://www.w3.org/TR/prov-dm/) refers to as core structures. We only look at directly asserted information about resources in the dataset (i.e. no inference was performed before calculating these statistics).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "We note that the code for our analysis is embeded within this document but is by default hidden for easier reading.\n",
       "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "display(HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "We note that the code for our analysis is embeded within this document but is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, all code is available [online](https://github.com/pgroth/prov-wod-analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "nsr = requests.get(\"http://index.lodlaundromat.org/ns2d/\", params={\"uri\":\"http://www.w3.org/ns/prov#\"})\n",
    "total_prov_docs = nsr.json()[\"totalResults\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nsr = requests.get(\"http://index.lodlaundromat.org/ns2d/\", params={\"uri\":\"http://www.w3.org/ns/prov#\",\"limit\":total_prov_docs} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from rdflib.namespace import RDFS, RDF\n",
    "from rdflib.namespace import Namespace\n",
    "from rdflib import Graph\n",
    "from rdflib import URIRef\n",
    "PROV = Namespace('http://www.w3.org/ns/prov#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entitySubclasses = []\n",
    "activitySubclasses = []\n",
    "agentSubclasses = []\n",
    "totalNumberOfEntities = 0\n",
    "totalNumberOfActivities = 0\n",
    "totalNumberOfAgents = 0\n",
    "numWasDerivedFrom = 0\n",
    "numUsed = 0\n",
    "numWGB = 0\n",
    "numWAW = 0\n",
    "numWasAttributedTo = 0\n",
    "\n",
    "for doc in nsr.json()[\"results\"]:\n",
    "    #print(doc)\n",
    "    headers = {'Accept': 'text/turtle'}\n",
    "    x = requests.get(\"http://ldf.lodlaundromat.org/\" + doc, headers=headers)\n",
    "    txt_res = x.text\n",
    "    tmpGraph = Graph()\n",
    "    tmpGraph.parse(io.StringIO(txt_res), format=\"turtle\")\n",
    "    #print(doc + \" \" + str(len(tmpGraph)))\n",
    "    for entityClass in tmpGraph.subjects(RDFS.subClassOf, PROV.Entity):\n",
    "        #print(entityClass)\n",
    "        entitySubclasses.append(entityClass)\n",
    "    for entity in tmpGraph.subjects(RDF.type, PROV.Entity):\n",
    "        totalNumberOfEntities = totalNumberOfEntities + 1\n",
    "    \n",
    "    for activityClass in tmpGraph.subjects(RDFS.subClassOf, PROV.Activity):\n",
    "        #print(activityClass)\n",
    "        activitySubclasses.append(activityClass)\n",
    "    \n",
    "    for activity in tmpGraph.subjects(RDF.type, PROV.Activity):\n",
    "        totalNumberOfActivities = totalNumberOfActivities + 1\n",
    "        \n",
    "    for agentClass in tmpGraph.subjects(RDFS.subClassOf, PROV.Agent):\n",
    "        #print(agentClass)\n",
    "        agentSubclasses.append(agentClass)\n",
    "        \n",
    "    for agent in tmpGraph.subjects(RDF.type, PROV.Agent):\n",
    "        totalNumberOfAgents = totalNumberOfAgents + 1\n",
    "    \n",
    "    ##look at relations\n",
    "    \n",
    "    for s,p,o in tmpGraph.triples( (None, PROV.wasDerivedFrom, None )):\n",
    "        numWasDerivedFrom = numWasDerivedFrom + 1\n",
    "\n",
    "    for s,p,o in tmpGraph.triples( (None, PROV.used, None )):\n",
    "        numUsed = numUsed + 1\n",
    "                            \n",
    "    for s,p,o in tmpGraph.triples( (None, PROV.wasGeneratedBy, None )):\n",
    "        numWGB = numWGB + 1\n",
    "                                  \n",
    "    for s,p,o in tmpGraph.triples( (None, PROV.wasAssociatedWith, None )):\n",
    "        numWAW = numWAW + 1\n",
    "                     \n",
    "    for s,p,o in tmpGraph.triples( (None, PROV.wasAttributedTo, None) ):                          \n",
    "        numWasAttributedTo = numWasAttributedTo + 1\n",
    "   \n",
    "        \n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Statistics \n",
       "We first look at how many times both the namespace is declared and how many resources are of a given core type.\n",
       "* The PROV namespace occurs in 1159 documents.\n",
       "* Number of Entites: 1214\n",
       "* Number of Activities: 283\n",
       "* Number of Agents: 641\n",
       "\n",
       "We also looked at the number of PROV edges that were used with the various documents.\n",
       "* Number of wasDerivedFrom edges: 23088\n",
       "* Number of used edges: 0\n",
       "* Number of wasGeneratedBy edges: 0\n",
       "* Number of wasAssociatedWith edges: 0\n",
       "* Number of wasAttributedTo edges: 0\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "output = \"### Statistics \\n\"\n",
    "output += \"We first look at how many times both the namespace is declared and how many resources are of a given core type.\\n\"\n",
    "output += \"* The PROV namespace occurs in \" + str(total_prov_docs) + \" documents.\\n\" \n",
    "output += \"* Number of Entites: \" + str(totalNumberOfEntities) + \"\\n\"\n",
    "output += \"* Number of Activities: \" + str(totalNumberOfActivities) + \"\\n\"\n",
    "output += \"* Number of Agents: \" + str(totalNumberOfAgents) + \"\\n\\n\"\n",
    "\n",
    "output += \"We also looked at the number of PROV edges that were used with the various documents.\\n\"\n",
    "output += \"* Number of wasDerivedFrom edges: \" + str(numWasDerivedFrom) + \"\\n\"\n",
    "output += \"* Number of used edges: \" + str(numUsed) + \"\\n\"\n",
    "output += \"* Number of wasGeneratedBy edges: \" + str(numWGB) + \"\\n\"\n",
    "output += \"* Number of wasAssociatedWith edges: \" + str(numWAW) + \"\\n\"\n",
    "output += \"* Number of wasAttributedTo edges: \" + str(numWasAttributedTo) + \"\\n\\n\"\n",
    "\n",
    "display(Markdown(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also note that PROV has been extended by 8 other ontologies as calculated by manual inspection of the extensions of the various core classes as listed in the appendix.\n",
    "\n",
    "### Conclusion\n",
    "This initial analysis shows some uptake within the Semantic Web community. However, while PROV is widely referenced within the community's literature, it appears, that direct usage of the standard could be improved (at least within the dataset represented by the LOD Laudromat). It should be noted that our analysis is preliminary and there is a much  room for further work. In particular, we aim to look at the indirect usage of PROV through usage by ontologies that extend it (e.g. The Provenance Vocabulary) or that map to it such as Dublin Core or [PAV](http://pav-ontology.github.io/pav/). Understanding such indirect usage will help us better understand the true state of provenance interoperability within Linked Data. Likewise, it would be interesting to perform network analysis to understand the role that PROV plays within the Linked Data network. \n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "* Beek, W. & Rietveld, L & Bazoobandi, H.R. & Wielemaker, J. & Schlobach, S.: LOD Laundromat: A Uniform Way of Publishing Other People's Dirty Data. Proceedings of the International Semantic Web Conference (2014).\n",
    "* Rietveld, L. & Beek, W. & Schlobach, S.: LOD Lab: Experiments at LOD Scale. Proceedings of the International Semantic Web Conference (2015).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix: Classes that subclass a PROV core class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subclasses of Entity\n",
      "http://www.gsi.dit.upm.es/ontologies/marl/ns#Opinion\n",
      "http://purl.org/net/p-plan#Entity\n",
      "http://www.w3.org/ns/prov#Plan\n",
      "http://www.w3.org/ns/prov#Bundle\n",
      "http://www.w3.org/ns/prov#Collection\n",
      "http://www.opmw.org/ontology/WorkflowExecutionArtifact\n",
      "http://purl.org/twc/vocab/vsr#Color\n",
      "http://www.co-ode.org/ontologies/ont.owl#Graphic\n",
      "http://purl.org/twc/vocab/vsr#Root\n",
      "http://purl.org/twc/vocab/vsr#Color\n",
      "http://www.co-ode.org/ontologies/ont.owl#Graphic\n",
      "http://purl.org/twc/vocab/vsr#Root\n",
      "http://purl.org/net/provenance/ns#DataItem\n",
      "http://purl.org/net/provenance/ns#File\n",
      "http://purl.org/net/provenance/ns#Immutable\n",
      "http://purl.org/net/provenance/ns#File\n",
      "http://purl.org/net/provenance/ns#Immutable\n",
      "http://purl.org/net/provenance/ns#DataItem\n",
      "Subclasses of Activity\n",
      "http://www.gsi.dit.upm.es/ontologies/marl/ns#SentimentAnalysis\n",
      "http://spitfire-project.eu/ontology/ns/Activity\n",
      "http://www.w3.org/ns/org#ChangeEvent\n",
      "http://purl.org/net/p-plan#Activity\n",
      "http://www.opmw.org/ontology/WorkflowExecutionProcess\n",
      "http://www.w3.org/ns/org#ChangeEvent\n",
      "http://purl.org/net/provenance/ns#DataCreation\n",
      "http://purl.org/net/provenance/ns#DataAccess\n",
      "http://purl.org/net/provenance/ns#DataCreation\n",
      "http://purl.org/net/provenance/ns#DataAccess\n",
      "Subclasses of Agent\n",
      "http://spitfire-project.eu/ontology/ns/Agent\n",
      "http://purl.org/net/provenance/types#DataCreator\n",
      "http://purl.org/net/provenance/ns#HumanAgent\n",
      "http://purl.org/net/provenance/ns#HumanAgent\n"
     ]
    }
   ],
   "source": [
    "print(\"Subclasses of Entity\")\n",
    "for i in entitySubclasses:\n",
    "    print(i)\n",
    "print(\"Subclasses of Activity\")\n",
    "for i in activitySubclasses:\n",
    "    print(i)\n",
    "print(\"Subclasses of Agent\")\n",
    "for i in agentSubclasses:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
